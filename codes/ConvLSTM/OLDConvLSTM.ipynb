{"cells":[{"cell_type":"code","execution_count":1,"id":"ykQl-yRuJLmr","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285868,"status":"ok","timestamp":1718279320802,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"ykQl-yRuJLmr","outputId":"1384aba7-8ee4-4426-ea45-141ae8ddc3f7"},"outputs":[],"source":["#!gdown 1fYtaFcGKSL8ykJFbewAFsFf9C4aW0DuV\n","#!gdown 1VILdkCRWsDTrN9DPeMLh8jlibAoBLzy-\n","#!gdown 197pDAI8KVsiDAA1xaPbitZpmvzh9CDqT\n","#!gdown 1XqgXAtxWUdnBJnvQTtEr8JpBkVi3JuSC\n","#!gdown 1_DVttDvwxCm_QGDxU2tbaaclWKd1VCau"]},{"cell_type":"code","execution_count":2,"id":"ccjyLAe1JYbR","metadata":{"executionInfo":{"elapsed":717,"status":"ok","timestamp":1718279321504,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"ccjyLAe1JYbR"},"outputs":[],"source":["#%mkdir -p /data\n","#%mv /content/*.hdf5 /data/\n","#%mv /content/*.npy /data/"]},{"cell_type":"code","execution_count":3,"id":"IZps4vwbH9zu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1801,"status":"ok","timestamp":1718279323300,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"IZps4vwbH9zu","outputId":"6d36bf62-c3d4-4707-cd99-af6aaba69f91"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/gdrive/')\n","#import sys\n","#sys.path.append('/content/gdrive/MyDrive/Universidad/VIU/TFM/notebooks')"]},{"cell_type":"code","execution_count":4,"id":"81eef624","metadata":{"executionInfo":{"elapsed":10482,"status":"ok","timestamp":1718279333780,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"81eef624"},"outputs":[],"source":["%%capture\n","%pip install torch torchvision h5py xarray matplotlib netcdf4"]},{"cell_type":"code","execution_count":5,"id":"b54f5dc8","metadata":{"executionInfo":{"elapsed":16651,"status":"ok","timestamp":1718279350426,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"b54f5dc8"},"outputs":[],"source":["import random\n","import time\n","import os\n","import datetime\n","import itertools\n","import math\n","import sys\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import h5py\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import xarray as xr\n","\n","sys.path.append('../common')\n","import common\n","from ConvLSTMmodels import ConvLSTM, EncoderRNN, VideoDataset, ConvLSTMEncoderDecoder"]},{"cell_type":"code","execution_count":6,"id":"bc83f9ff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1718279350427,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"bc83f9ff","outputId":"cde309e0-3657-4913-c69c-0b4233f62f8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["pytorch version: 2.3.1+cu121\n","GPUs not available. Only CPU.\n"]}],"source":["# check tensorflow version\n","print(\"pytorch version:\", torch.__version__)\n","# check available gpu\n","if torch.cuda.is_available():\n","    gpus =  torch.cuda.get_device_name(torch.cuda.current_device())\n","    print(f\"Available GPUs: {gpus}\")\n","else:\n","    print(\"GPUs not available. Only CPU.\")"]},{"cell_type":"code","execution_count":7,"id":"0612dccb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718279350427,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"0612dccb","outputId":"fbe9980f-b6e7-44b2-a44e-67f47028494b","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data_folder: /home/javgat/Repos/Otros/presente/data\n","data_path: /home/javgat/Repos/Otros/presente/data/video_prediction_dataset.hdf5\n","output_folder: /home/javgat/Repos/Otros/presente/codes/ConvLSTM/save/ConvLSTM\n"]}],"source":["cwd = os.getcwd()\n","pardir = os.path.dirname(os.path.dirname(cwd))\n","data_folder = os.path.join(pardir,'data')\n","data_path = os.path.join(data_folder,'video_prediction_dataset.hdf5')\n","model_name = 'ConvLSTM'\n","output_folder = os.path.join(cwd,\"save\", model_name)\n","if not os.path.isdir(output_folder):\n","    os.makedirs(output_folder)\n","print(\"data_folder:\", data_folder)\n","print(\"data_path:\", data_path)\n","print(\"output_folder:\", output_folder)"]},{"cell_type":"code","execution_count":8,"id":"4b14b74e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718279350427,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"4b14b74e","outputId":"07b789b8-e740-4c66-e6c8-bd7ae1a15e82"},"outputs":[{"name":"stdout","output_type":"stream","text":["<HDF5 group \"/test\" (4 members)>\n","<HDF5 dataset \"images_log\": shape (4467, 16, 64, 64, 3), type \"|u1\">\n","<HDF5 dataset \"images_pred\": shape (4467, 15, 64, 64, 3), type \"|u1\">\n","<HDF5 dataset \"pv_log\": shape (4467, 16), type \"<f4\">\n","<HDF5 dataset \"pv_pred\": shape (4467, 15), type \"<f4\">\n","<HDF5 group \"/trainval\" (4 members)>\n","<HDF5 dataset \"images_log\": shape (53336, 16, 64, 64, 3), type \"|u1\">\n","<HDF5 dataset \"images_pred\": shape (53336, 15, 64, 64, 3), type \"|u1\">\n","<HDF5 dataset \"pv_log\": shape (53336, 16), type \"<f4\">\n","<HDF5 dataset \"pv_pred\": shape (53336, 15), type \"<f4\">\n"]}],"source":["def get_all(name):\n","    # show structure of the hdf5 data\n","    if name!=None:\n","        print(forecast_dataset[name])\n","\n","# generate handler for the hdf5 data\n","with h5py.File(data_path, 'r') as forecast_dataset:\n","    forecast_dataset.visit(get_all)"]},{"cell_type":"code","execution_count":9,"id":"304f1592","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":580,"status":"ok","timestamp":1718279351004,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"304f1592","outputId":"4c31a2ab-c8e9-46a0-9d4c-d5c8dfc4d22c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['test', 'trainval']\n"]}],"source":["with h5py.File(data_path, 'r') as fds:\n","    group_names = list(fds.keys())\n","    print(group_names)\n","\n","dss = {}\n","for gname in group_names:\n","    dss[gname] = xr.open_dataset(data_path, group=gname)"]},{"cell_type":"code","execution_count":10,"id":"f46ff513","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718279351005,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"f46ff513","outputId":"a7a33df6-6f86-4dd8-d4d8-b2b1015a1dbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["<xarray.DataArray 'images_log' (phony_dim_0: 4467, phony_dim_1: 16,\n","                                phony_dim_2: 64, phony_dim_3: 64, phony_dim_4: 3)> Size: 878MB\n","[878247936 values with dtype=uint8]\n","Dimensions without coordinates: phony_dim_0, phony_dim_1, phony_dim_2,\n","                                phony_dim_3, phony_dim_4\n"]}],"source":["print(dss['test']['images_log'])"]},{"cell_type":"code","execution_count":11,"id":"Mf-ZtM6JPnUL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1718279351446,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"Mf-ZtM6JPnUL","outputId":"45fae1d3-e40c-4723-c6a0-ace19e4969bf"},"outputs":[{"data":{"text/plain":["(4467, 16, 64, 64, 3)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dss['test']['images_log'].shape"]},{"cell_type":"code","execution_count":12,"id":"3e69b26e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1718279351446,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"3e69b26e","outputId":"2037a968-4fe5-4dc1-ab50-257a9a0fd2d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","times_curr_train.shape: (53336,)\n","images_log_train.shape: (53336, 16, 64, 64, 3)\n","images_pred_train.shape: (53336, 15, 64, 64, 3)\n","times_curr_test.shape: (4467,)\n","images_log_test.shape: (4467, 16, 64, 64, 3)\n","images_pred_test.shape: (4467, 15, 64, 64, 3)\n","--------------------------------------------------\n","image side length: 64\n","number of log frames: 16\n","number of pred frames: 15\n","number of color channels: 3\n","context(log) image dimension: [16, 64, 64, 3]\n","future(pred) image dimension: [15, 64, 64, 3]\n"]}],"source":["times_curr_train = np.load(os.path.join(data_folder,\"times_curr_trainval.npy\"),allow_pickle=True)\n","times_curr_test = np.load(os.path.join(data_folder,\"times_curr_test.npy\"),allow_pickle=True)\n","\n","print('-'*50)\n","print(\"times_curr_train.shape:\", times_curr_train.shape)\n","print(\"images_log_train.shape:\", dss['trainval']['images_log'].shape)\n","print(\"images_pred_train.shape:\", dss['trainval']['images_pred'].shape)\n","print(\"times_curr_test.shape:\", times_curr_test.shape)\n","print(\"images_log_test.shape:\", dss['test']['images_log'].shape)\n","print(\"images_pred_test.shape:\", dss['test']['images_pred'].shape)\n","print('-'*50)\n","\n","# get the input dimension for constructing the model\n","num_log_frame = dss['trainval']['images_log'].shape[1]\n","img_side_len = dss['trainval']['images_log'].shape[2]\n","num_color_channel = dss['trainval']['images_log'].shape[4]\n","num_pred_frame = dss['trainval']['images_pred'].shape[1]\n","image_log_dim = [num_log_frame,img_side_len,img_side_len,num_color_channel]\n","image_pred_dim = [num_pred_frame,img_side_len,img_side_len,num_color_channel]\n","\n","print(\"image side length:\", img_side_len)\n","print(\"number of log frames:\", num_log_frame)\n","print(\"number of pred frames:\", num_pred_frame)\n","print(\"number of color channels:\", num_color_channel)\n","print(\"context(log) image dimension:\", image_log_dim)\n","print(\"future(pred) image dimension:\", image_pred_dim)"]},{"cell_type":"markdown","id":"e434c20b","metadata":{"id":"e434c20b"},"source":["### dataloader"]},{"cell_type":"code","execution_count":13,"id":"4fba4993","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1718279351446,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"4fba4993","outputId":"026cd924-f78a-428b-f673-68548b4720f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n","nepochs: 50\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","batch_size_train = 16\n","batch_size_test = 64\n","if device.type == \"cpu\":\n","  batch_size_train = 4\n","  batch_size_test = 4\n","nepochs = 50\n","print('nepochs:',nepochs)\n","print_every = 1\n","eval_every = 5"]},{"cell_type":"code","execution_count":14,"id":"d3fa282d","metadata":{},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Lambda(lambda x: x.float()),\n","    transforms.Normalize(mean=[0.5], std=[0.5])  # Example normalization\n","])"]},{"cell_type":"code","execution_count":15,"id":"90f1b69e","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718279351446,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"90f1b69e"},"outputs":[],"source":["# Create Dataset and DataLoader\n","train_dataset = VideoDataset(dss['trainval']['images_log'], dss['trainval']['images_pred'], transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n","\n","test_dataset = VideoDataset(dss['test']['images_log'], dss['test']['images_pred'], transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)"]},{"cell_type":"markdown","id":"1e650dd2","metadata":{"id":"1e650dd2"},"source":["### Training and Validate the Model"]},{"cell_type":"markdown","id":"6eabffbe","metadata":{},"source":["#### Define train & evaluate"]},{"cell_type":"code","execution_count":16,"id":"-dPttXDPTmuq","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718279351446,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"-dPttXDPTmuq"},"outputs":[],"source":["def train_on_minibatch(input_tensor, target_tensor, model, optimizer, criterion, teacher_forcing_ratio, accumulation_steps, batch_idx):\n","    target_length = target_tensor.shape[1]\n","    pred = model(input_tensor, target_length)\n","    pred = pred\n","    print(pred.shape)\n","    print(target_tensor.shape)\n","    loss = criterion(pred, target_tensor)\n","    loss = loss / accumulation_steps\n","    loss.backward(retain_graph=True)\n","    \n","    # Update optimizer and zero grad only when accumulation step is reached\n","    if (batch_idx + 1) % accumulation_steps == 0:\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    \n","    return loss.item() / target_tensor.size(1)"]},{"cell_type":"code","execution_count":17,"id":"28a204ea","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718279351446,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"28a204ea"},"outputs":[],"source":["def evaluate(model, loader, device, times_curr_test, img_side_len, num_color_channel):\n","    model.eval()\n","    def compute_metrics(prediction, target):\n","        mse = np.mean((prediction - target) ** 2, axis=1).sum()\n","        mae = np.mean(np.abs(prediction - target), axis=1).sum()\n","        return mse, mae\n","\n","    print(\"Validation start...\")\n","    total_mse, total_mae = 0, 0\n","    start_time = time.time()\n","    predictions = []\n","    indices = []\n","\n","    num_val_samples = len(times_curr_test)\n","    with torch.no_grad():\n","        for idx, (inseq, outseq) in enumerate(loader):\n","            batch_indices = idx\n","            input_tensor = inseq.to(device)\n","            target_tensor = outseq.to(device)\n","            target_length = target_tensor.shape[1]\n","            pred = model(input_tensor, target_length)\n","            pred = pred[0]\n","\n","            # Compute metrics for the current batch\n","            mse_batch, mae_batch = compute_metrics(pred, target_tensor)\n","            total_mse += mse_batch\n","            total_mae += mae_batch\n","\n","            indices.extend(batch_indices)\n","\n","    # Compute overall metrics\n","    predictions = np.concatenate(predictions, axis=0)\n","    mse_per_frame = total_mse / num_val_samples\n","    mae_per_frame = total_mae / num_val_samples\n","    mse_per_pixel = mse_per_frame / (img_side_len * img_side_len * num_color_channel)\n","    mae_per_pixel = mae_per_frame / (img_side_len * img_side_len * num_color_channel)\n","\n","    print(f'Eval MSE per frame: {mse_per_frame:.4f}')\n","    print(f'Eval MAE per frame: {mae_per_frame:.4f}')\n","    print(f'Eval MSE per pixel: {mse_per_pixel:.6f}')\n","    print(f'Eval MAE per pixel: {mae_per_pixel:.6f}')\n","    print(f'Time: {time.time() - start_time:.2f}s')\n","\n","    return mse_per_frame, mae_per_frame, mse_per_pixel, mae_per_pixel, predictions, indices\n"]},{"cell_type":"code","execution_count":18,"id":"iWeraNBzUmq1","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718279351446,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"iWeraNBzUmq1"},"outputs":[],"source":["def trainIters(model, nepochs, train_loader, test_loader, device, print_every=10, eval_every=10, name='', accumulation_steps=4):\n","  train_losses = []\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","  scheduler_enc = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1)\n","  criterion = nn.MSELoss()\n","  lrs = []\n","\n","  for epoch in range(nepochs):\n","    model.train()\n","    t0 = time.time()\n","    loss_epoch = 0\n","    teacher_forcing_ratio = max(0, 1 - epoch * 0.03)\n","\n","    for batch_idx, (input_seq, output_seq) in enumerate(train_loader):\n","      print(batch_idx)\n","      input_tensor = input_seq.to(device)\n","      target_tensor = output_seq.to(device)\n","      loss = train_on_minibatch(input_tensor, target_tensor, model, optimizer, criterion, teacher_forcing_ratio, accumulation_steps, batch_idx)\n","      loss_epoch += loss\n","\n","    # Ensure any remaining gradients are applied\n","    if (batch_idx + 1) % accumulation_steps != 0:\n","      optimizer.step()\n","      optimizer.zero_grad()\n","\n","    train_losses.append(loss_epoch)\n","\n","    if (epoch + 1) % print_every == 0:\n","      print('-' * 50)\n","      print(f'Epoch {epoch + 1} | Loss: {loss_epoch:.4f} | Time: {time.time() - t0:.2f}s')\n","      print(\"Saving model...\")\n","      torch.save(model.state_dict(), f'save/{name}/encoder.pth')\n","\n","    if (epoch + 1) % eval_every == 0:\n","      mse_per_frame, _, mse_per_pixel, _, _, _ = evaluate(model, test_loader)\n","      scheduler_enc.step(mse_per_frame)\n","\n","    lrs.append(scheduler_enc.get_last_lr())\n","\n","  return train_losses, lrs"]},{"cell_type":"markdown","id":"751610bf","metadata":{},"source":["#### Actually train"]},{"cell_type":"code","execution_count":19,"id":"e7a25834","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718279351447,"user":{"displayName":"Javgat π","userId":"05200661440226510528"},"user_tz":-120},"id":"e7a25834","outputId":"fb9e0140-ed31-48af-e397-02309a58eccf"},"outputs":[{"name":"stdout","output_type":"stream","text":["model  66547\n"]}],"source":["input_dim = 3\n","hidden_dims = [16, 16] #[128,128,64]\n","num_layers = 2 #3\n","kernel_size = (3, 3)\n","batch_first = True\n","#convlstm = ConvLSTM(input_dim, hidden_dims, kernel_size, num_layers, batch_first)\n","#model = EncoderRNN(convcell, device, nc=3)\n","model = ConvLSTMEncoderDecoder(input_dim, hidden_dims, kernel_size, num_layers, batch_first)\n","model = model.to(device)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print('model ', count_parameters(model) )"]},{"cell_type":"code","execution_count":20,"id":"a1279531","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1279531","outputId":"f982968c-ad93-48c8-95c1-c79469a8f737","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","15\n","torch.Size([4, 1, 16, 64, 64])\n","0\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","1\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","2\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","3\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","4\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","5\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","6\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","7\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","8\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","9\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","10\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","11\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","12\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","13\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","14\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","1\n","15\n","torch.Size([4, 1, 16, 64, 64])\n","0\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","1\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","2\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","3\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","4\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","5\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","6\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","7\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","8\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","9\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","10\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","11\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","12\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","13\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","14\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","2\n","15\n","torch.Size([4, 1, 16, 64, 64])\n","0\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","1\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","2\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","3\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","4\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","5\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","6\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","7\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","8\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","9\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","10\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","11\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","12\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","13\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","14\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","3\n","15\n","torch.Size([4, 1, 16, 64, 64])\n","0\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","1\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","2\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","3\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","4\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","5\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","6\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","7\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","8\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","9\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","10\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","11\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","12\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","13\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","14\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","4\n","15\n","torch.Size([4, 1, 16, 64, 64])\n","0\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","1\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","2\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","3\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","4\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","5\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","6\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","7\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","8\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","9\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","10\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","11\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","12\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","13\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","14\n","torch.Size([4, 1, 16, 64, 64])\n","torch.Size([4, 1, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n","torch.Size([4, 15, 3, 64, 64])\n"]},{"ename":"RuntimeError","evalue":"one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [64, 32, 3, 3]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss, learning_rates \u001b[38;5;241m=\u001b[39m \u001b[43mtrainIters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[18], line 18\u001b[0m, in \u001b[0;36mtrainIters\u001b[0;34m(model, nepochs, train_loader, test_loader, device, print_every, eval_every, name, accumulation_steps)\u001b[0m\n\u001b[1;32m     16\u001b[0m   input_tensor \u001b[38;5;241m=\u001b[39m input_seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m   target_tensor \u001b[38;5;241m=\u001b[39m output_seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_minibatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m   loss_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Ensure any remaining gradients are applied\u001b[39;00m\n","Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mtrain_on_minibatch\u001b[0;34m(input_tensor, target_tensor, model, optimizer, criterion, teacher_forcing_ratio, accumulation_steps, batch_idx)\u001b[0m\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, target_tensor)\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m accumulation_steps\n\u001b[0;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Update optimizer and zero grad only when accumulation step is reached\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m~/Repos/Otros/presente/.venv/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Repos/Otros/presente/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Repos/Otros/presente/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [64, 32, 3, 3]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."]}],"source":["train_loss, learning_rates = trainIters(model, nepochs, train_loader, test_loader, device, print_every, eval_every, model_name)"]},{"cell_type":"markdown","id":"09228ad7","metadata":{"id":"09228ad7"},"source":["        ### Save Predicted Images from Validation Set"]},{"cell_type":"code","execution_count":null,"id":"58dbe738","metadata":{"id":"58dbe738"},"outputs":[],"source":["model.load_state_dict(torch.load('save/{0}/encoder.pth'.format(model_name)))\n","model.eval()\n","mse_per_frame, mae_per_frame, mse_per_pixel, mae_per_pixel, predictions, indices = evaluate(model,test_loader)"]},{"cell_type":"code","execution_count":null,"id":"eec801ad","metadata":{"id":"eec801ad"},"outputs":[],"source":["print(predictions.shape)\n","predictions = predictions.transpose((0,1,3,4,2))\n","print(predictions.shape)"]},{"cell_type":"code","execution_count":null,"id":"3bfca67f","metadata":{"collapsed":true,"id":"3bfca67f","jupyter":{"outputs_hidden":true}},"outputs":[],"source":["np.save('save/{0}/predicted_images.npy'.format(model_name), predictions)"]},{"cell_type":"markdown","id":"64e50e43","metadata":{"id":"64e50e43"},"source":["### Visualize Some Sample Predictions"]},{"cell_type":"code","execution_count":null,"id":"4721f87c","metadata":{"id":"4721f87c","scrolled":true},"outputs":[],"source":["random.seed(0)\n","select_num_samples = 30\n","select_idx = random.sample(np.arange(len(predictions)).tolist(),select_num_samples)"]},{"cell_type":"code","execution_count":null,"id":"1d02a075","metadata":{"id":"1d02a075"},"outputs":[],"source":["for i in range(select_num_samples):\n","    print(\"-\"*50,\"sample \",str(i+1), \"-\"*50)\n","    f, ax = plt.subplots(2,8)\n","    f.set_size_inches(24,6)\n","    ax[0,0].imshow(images_log_test[select_idx[i]][0][:,:,::-1])\n","    ax[0,0].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=15))\n","    ax[0,1].imshow(images_log_test[select_idx[i]][2][:,:,::-1])\n","    ax[0,1].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=11))\n","    ax[0,2].imshow(images_log_test[select_idx[i]][4][:,:,::-1])\n","    ax[0,2].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=7))\n","    ax[0,3].imshow(images_log_test[select_idx[i]][7][:,:,::-1])\n","    ax[0,3].set_title(times_curr_test[select_idx[i]]-datetime.timedelta(minutes=1))\n","    ax[0,4].imshow(images_pred_test[select_idx[i]][0][:,:,::-1])\n","    ax[0,4].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=1))\n","    ax[0,5].imshow(images_pred_test[select_idx[i]][2][:,:,::-1])\n","    ax[0,5].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=5))\n","    ax[0,6].imshow(images_pred_test[select_idx[i]][4][:,:,::-1])\n","    ax[0,6].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=9))\n","    ax[0,7].imshow(images_pred_test[select_idx[i]][7][:,:,::-1])\n","    ax[0,7].set_title(times_curr_test[select_idx[i]]+datetime.timedelta(minutes=15))\n","\n","    ax[1,4].imshow(predictions[select_idx[i]][0][:,:,::-1])\n","    ax[1,5].imshow(predictions[select_idx[i]][2][:,:,::-1])\n","    ax[1,6].imshow(predictions[select_idx[i]][4][:,:,::-1])\n","    ax[1,7].imshow(predictions[select_idx[i]][7][:,:,::-1])\n","\n","    ax[0,0].axis('off')\n","    ax[0,1].axis('off')\n","    ax[0,2].axis('off')\n","    ax[0,3].axis('off')\n","    ax[0,4].axis('off')\n","    ax[0,5].axis('off')\n","    ax[0,6].axis('off')\n","    ax[0,7].axis('off')\n","    ax[1,0].axis('off')\n","    ax[1,1].axis('off')\n","    ax[1,2].axis('off')\n","    ax[1,3].axis('off')\n","    ax[1,4].axis('off')\n","    ax[1,5].axis('off')\n","    ax[1,6].axis('off')\n","    ax[1,7].axis('off')\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"2ee9d9bd","metadata":{"collapsed":true,"id":"2ee9d9bd","jupyter":{"outputs_hidden":true}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
