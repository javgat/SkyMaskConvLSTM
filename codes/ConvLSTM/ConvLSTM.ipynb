{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install torch torchvision h5py xarray matplotlib netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import itertools\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append('../common')\n",
    "import common\n",
    "from common import VideoDataset\n",
    "from ConvLSTMmodels import ConvLSTM, EncoderRNN, ConvLSTMEncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.3.1+cu121\n",
      "GPUs not available. Only CPU.\n"
     ]
    }
   ],
   "source": [
    "# check tensorflow version\n",
    "print(\"pytorch version:\", torch.__version__)\n",
    "# check available gpu\n",
    "if torch.cuda.is_available():\n",
    "    gpus =  torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "    print(f\"Available GPUs: {gpus}\")\n",
    "else:\n",
    "    print(\"GPUs not available. Only CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder: /home/javgat/Repos/Otros/presente/data\n",
      "data_path: /home/javgat/Repos/Otros/presente/data/video_prediction_dataset.hdf5\n",
      "output_folder: /home/javgat/Repos/Otros/presente/codes/ConvLSTM/save/ConvLSTM\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "pardir = os.path.dirname(os.path.dirname(cwd))\n",
    "data_folder = os.path.join(pardir,'data')\n",
    "data_path = os.path.join(data_folder,'video_prediction_dataset.hdf5')\n",
    "model_name = 'ConvLSTM'\n",
    "output_folder = os.path.join(cwd,\"save\", model_name)\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "print(\"data_folder:\", data_folder)\n",
    "print(\"data_path:\", data_path)\n",
    "print(\"output_folder:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 group \"/test\" (4 members)>\n",
      "<HDF5 dataset \"images_log\": shape (4467, 16, 64, 64, 3), type \"|u1\">\n",
      "<HDF5 dataset \"images_pred\": shape (4467, 15, 64, 64, 3), type \"|u1\">\n",
      "<HDF5 dataset \"pv_log\": shape (4467, 16), type \"<f4\">\n",
      "<HDF5 dataset \"pv_pred\": shape (4467, 15), type \"<f4\">\n",
      "<HDF5 group \"/trainval\" (4 members)>\n",
      "<HDF5 dataset \"images_log\": shape (53336, 16, 64, 64, 3), type \"|u1\">\n",
      "<HDF5 dataset \"images_pred\": shape (53336, 15, 64, 64, 3), type \"|u1\">\n",
      "<HDF5 dataset \"pv_log\": shape (53336, 16), type \"<f4\">\n",
      "<HDF5 dataset \"pv_pred\": shape (53336, 15), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "def get_all(name):\n",
    "    # show structure of the hdf5 data\n",
    "    if name!=None:\n",
    "        print(forecast_dataset[name])\n",
    "\n",
    "# generate handler for the hdf5 data\n",
    "with h5py.File(data_path, 'r') as forecast_dataset:\n",
    "    forecast_dataset.visit(get_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'trainval']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(data_path, 'r') as fds:\n",
    "    group_names = list(fds.keys())\n",
    "    print(group_names)\n",
    "\n",
    "dss = {}\n",
    "for gname in group_names:\n",
    "    dss[gname] = xr.open_dataset(data_path, group=gname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'images_log' (phony_dim_0: 4467, phony_dim_1: 16,\n",
      "                                phony_dim_2: 64, phony_dim_3: 64, phony_dim_4: 3)> Size: 878MB\n",
      "[878247936 values with dtype=uint8]\n",
      "Dimensions without coordinates: phony_dim_0, phony_dim_1, phony_dim_2,\n",
      "                                phony_dim_3, phony_dim_4\n",
      "(4467, 16, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dss['test']['images_log'])\n",
    "print(dss['test']['images_log'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "times_curr_train.shape: (53336,)\n",
      "images_log_train.shape: (53336, 16, 64, 64, 3)\n",
      "images_pred_train.shape: (53336, 15, 64, 64, 3)\n",
      "times_curr_test.shape: (4467,)\n",
      "images_log_test.shape: (4467, 16, 64, 64, 3)\n",
      "images_pred_test.shape: (4467, 15, 64, 64, 3)\n",
      "--------------------------------------------------\n",
      "image side length: 64\n",
      "number of log frames: 16\n",
      "number of pred frames: 15\n",
      "number of color channels: 3\n",
      "context(log) image dimension: [16, 64, 64, 3]\n",
      "future(pred) image dimension: [15, 64, 64, 3]\n"
     ]
    }
   ],
   "source": [
    "times_curr_train = np.load(os.path.join(data_folder,\"times_curr_trainval.npy\"),allow_pickle=True)\n",
    "times_curr_test = np.load(os.path.join(data_folder,\"times_curr_test.npy\"),allow_pickle=True)\n",
    "\n",
    "print('-'*50)\n",
    "print(\"times_curr_train.shape:\", times_curr_train.shape)\n",
    "print(\"images_log_train.shape:\", dss['trainval']['images_log'].shape)\n",
    "print(\"images_pred_train.shape:\", dss['trainval']['images_pred'].shape)\n",
    "print(\"times_curr_test.shape:\", times_curr_test.shape)\n",
    "print(\"images_log_test.shape:\", dss['test']['images_log'].shape)\n",
    "print(\"images_pred_test.shape:\", dss['test']['images_pred'].shape)\n",
    "print('-'*50)\n",
    "\n",
    "# get the input dimension for constructing the model\n",
    "num_log_frame = dss['trainval']['images_log'].shape[1]\n",
    "img_side_len = dss['trainval']['images_log'].shape[2]\n",
    "num_color_channel = dss['trainval']['images_log'].shape[4]\n",
    "num_pred_frame = dss['trainval']['images_pred'].shape[1]\n",
    "image_log_dim = [num_log_frame,img_side_len,img_side_len,num_color_channel]\n",
    "image_pred_dim = [num_pred_frame,img_side_len,img_side_len,num_color_channel]\n",
    "\n",
    "print(\"image side length:\", img_side_len)\n",
    "print(\"number of log frames:\", num_log_frame)\n",
    "print(\"number of pred frames:\", num_pred_frame)\n",
    "print(\"number of color channels:\", num_color_channel)\n",
    "print(\"context(log) image dimension:\", image_log_dim)\n",
    "print(\"future(pred) image dimension:\", image_pred_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.float()),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Example normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "batch_size_train = 16\n",
    "batch_size_test = 64\n",
    "if device.type == \"cpu\":\n",
    "  batch_size_train = 4\n",
    "  batch_size_test = 4\n",
    "print(batch_size_train, batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "train_dataset = VideoDataset(dss['trainval']['images_log'], dss['trainval']['images_pred'], transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_dataset = VideoDataset(dss['test']['images_log'], dss['test']['images_pred'], transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining training & evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nepochs: 50\n"
     ]
    }
   ],
   "source": [
    "nepochs = 50\n",
    "print('nepochs:',nepochs)\n",
    "print_every = 1\n",
    "eval_every = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
